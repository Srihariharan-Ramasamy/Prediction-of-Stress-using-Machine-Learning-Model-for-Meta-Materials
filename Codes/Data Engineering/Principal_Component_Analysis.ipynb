{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f85c2-884f-4d4d-92bd-9f6507c6a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_path = Path(r\"G:\\Other computers\\Dell G3\\Universitat\\2nd Semester\\MLMM\\New\\feature_engineered_data.csv\")\n",
    "\n",
    "# Load data\n",
    "df_all = pd.read_csv(csv_path, sep=\";\")\n",
    "print(df_all.shape)\n",
    "# Use ALL columns except the last one (bucket).\n",
    "# Prefer explicit drop if column is named 'bucket'; fall back to iloc if needed.\n",
    "if 'bucket' in df_all.columns:\n",
    "    X_df = df_all.drop(columns=['bucket'])\n",
    "else:\n",
    "    X_df = df_all.iloc[:, :-1]\n",
    "\n",
    "# Convert to numpy\n",
    "X = X_df.values\n",
    "\n",
    "# Standardize\n",
    "scaler_all = StandardScaler()\n",
    "X_scaled = scaler_all.fit_transform(X)\n",
    "\n",
    "# Fit PCA to full dimensionality (let PCA decide max)\n",
    "pca_full = PCA(n_components=None, random_state=42)\n",
    "pca_full.fit(X_scaled)\n",
    "\n",
    "explained = pca_full.explained_variance_ratio_\n",
    "cum_explained = np.cumsum(explained)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(range(1, len(cum_explained)+1), cum_explained, marker='o')\n",
    "plt.axhline(0.9059, linestyle='--')  # reference line at 90%\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Cumulative explained variance\")\n",
    "plt.title(\"PCA: cumulative explained variance\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# Print a quick table (first 25 PCs)\n",
    "print(\"PC  |  VarRatio  |  Cumulative\")\n",
    "for i, (vr, cv) in enumerate(zip(explained, cum_explained), start=1):\n",
    "    if i <= 25 or i == len(explained):\n",
    "        print(f\"{i:>3} |  {vr:8.4f} |  {cv:9.4f}\")\n",
    "print(f\"\\nTotal components available: {len(explained)}\")\n",
    "print(f\"Input features used: {X_df.shape[1]} (excluded column: 'bucket')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a74fb-0d67-4f93-ab18-2de4d45007cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "csv_path = Path(r\"G:\\Other computers\\Dell G3\\Universitat\\2nd Semester\\MLMM\\New\\feature_engineered_data.csv\")\n",
    "target_variance = 0.90\n",
    "\n",
    "# Load\n",
    "df_all = pd.read_csv(csv_path, sep=\";\")\n",
    "\n",
    "if 'bucket' in df_all.columns:\n",
    "    feature_df = df_all.drop(columns=['bucket'])\n",
    "else:\n",
    "    feature_df = df_all.iloc[:, :-1]\n",
    "\n",
    "X = feature_df.values\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Fit full PCA to measure variance curve\n",
    "pca_probe = PCA(n_components=None, random_state=42)\n",
    "pca_probe.fit(X_scaled)\n",
    "\n",
    "explained = pca_probe.explained_variance_ratio_\n",
    "cum_explained = np.cumsum(explained)\n",
    "\n",
    "# Pick the smallest k reaching the target variance\n",
    "k = int(np.searchsorted(cum_explained, target_variance) + 1)\n",
    "k = min(k, X_scaled.shape[1])  # safety\n",
    "\n",
    "print(f\"Target variance = {target_variance:.2%}\")\n",
    "print(f\"Optimal k = {k} components (cumulative variance = {cum_explained[k-1]:.4f})\")\n",
    "\n",
    "# Fit PCA with optimal k and transform\n",
    "pca_opt = PCA(n_components=k, random_state=42)\n",
    "pcs = pca_opt.fit_transform(X_scaled)\n",
    "\n",
    "# Assemble output\n",
    "pc_cols = [f\"PC{i}\" for i in range(1, k+1)]\n",
    "out_df = pd.concat(\n",
    "    [df_all.reset_index(drop=True),\n",
    "     pd.DataFrame(pcs, columns=pc_cols).reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save\n",
    "pca_out_path = csv_path.with_name(\"feature_engineered_with_pca_optimal.csv\")\n",
    "out_df.to_csv(pca_out_path, index=False)\n",
    "\n",
    "# Report\n",
    "print(\"Wrote:\", pca_out_path)\n",
    "print(\"Rows:\", len(out_df),\n",
    "      \"Original features (excluding 'bucket'):\", X.shape[1],\n",
    "      \"PCs:\", k)\n",
    "print(\"Explained variance by PC (first 15):\", [round(v,4) for v in explained[:15]])\n",
    "print(\"Cumulative explained variance at k:\", round(cum_explained[k-1], 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42c49e-66ec-4530-9891-495d20f962c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
