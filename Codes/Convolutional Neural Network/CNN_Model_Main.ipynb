{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1785b1ee-55cc-407f-b9e3-aee4a4a5f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa4286-ed47-436b-97e7-55fddc6103ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    \"images_dir\": r\"G:\\Other computers\\Dell G3\\Universitat\\2nd Semester\\MLMM\\New\\Project Folder\\Images_10k\",\n",
    "    \"labels_csv\": r\"G:\\Other computers\\Dell G3\\Universitat\\2nd Semester\\MLMM\\New\\Project Folder\\Final Dataset\\Dataset_CNN.csv\",\n",
    "\n",
    "    \"img_size\": 224,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 20,\n",
    "    \"lr\": 3e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"use_class_balancing\": True,  # if unstable, set False\n",
    "}\n",
    "\n",
    "BRACKET_NAMES = {0:\"0–25%\", 1:\"25–50%\", 2:\"50–75%\", 3:\"75–100%\"}\n",
    "print(\"Images dir exists?\", Path(CFG[\"images_dir\"]).exists())\n",
    "print(\"Labels csv exists?\", Path(CFG[\"labels_csv\"]).exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad2cdc-f52b-4f99-8108-842c235f3fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(CFG[\"labels_csv\"])\n",
    "assert {\"filename\",\"bracket\"}.issubset(labels.columns), \"labels.csv must have filename, bracket.\"\n",
    "\n",
    "labels[\"path\"] = labels[\"filename\"].apply(lambda f: str(Path(CFG[\"images_dir\"]) / f))\n",
    "missing = labels.loc[~labels[\"path\"].apply(lambda p: Path(p).exists())]\n",
    "assert missing.empty, f\"Missing images:\\n{missing.head()}\"\n",
    "\n",
    "y = labels[\"bracket\"].astype(int).values\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=SEED)\n",
    "train_idx, val_idx = next(sss.split(labels[\"path\"], y))\n",
    "train_df, val_df = labels.iloc[train_idx].reset_index(drop=True), labels.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "print(\"Train size:\", len(train_df), \" Val size:\", len(val_df))\n",
    "print(\"Train class counts:\", train_df[\"bracket\"].value_counts().sort_index().to_dict())\n",
    "print(\"Val   class counts:\", val_df[\"bracket\"].value_counts().sort_index().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e37e5a-1da2-428e-922b-031c703e0399",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_train = transforms.Compose([\n",
    "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15, fill=0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "tfm_val = transforms.Compose([\n",
    "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "class MetaCells(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "        img = Image.open(row[\"path\"]).convert(\"RGB\")\n",
    "        x = self.transform(img)\n",
    "        y = int(row[\"bracket\"])\n",
    "        return x, y\n",
    "\n",
    "train_ds = MetaCells(train_df, tfm_train)\n",
    "val_ds   = MetaCells(val_df,   tfm_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff3f8d4-1944-4801-b50d-6dae25e7cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG[\"use_class_balancing\"]:\n",
    "    counts = train_df[\"bracket\"].value_counts().sort_index().values.astype(float)\n",
    "    weights = 1.0 / counts\n",
    "    sample_w = train_df[\"bracket\"].map({i:w for i,w in enumerate(weights)}).values\n",
    "    sampler = WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)\n",
    "    train_dl = DataLoader(train_ds, batch_size=CFG[\"batch_size\"], sampler=sampler,\n",
    "                          num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "else:\n",
    "    train_dl = DataLoader(train_ds, batch_size=CFG[\"batch_size\"], shuffle=True,\n",
    "                          num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "val_dl   = DataLoader(val_ds,   batch_size=CFG[\"batch_size\"], shuffle=False,\n",
    "                      num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "print(\"Batches — train:\", len(train_dl), \" val:\", len(val_dl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96341302-af19-4b65-b462-68dd370996f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(num_classes=4):\n",
    "    m = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "model = make_model(4).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG[\"epochs\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy(logits, y):\n",
    "    return (logits.argmax(1) == y).float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d623303-28b7-42d0-b5df-32f5e38790f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "print(\"Batch shapes:\", xb.shape, yb.shape)\n",
    "xb, yb = xb.to(device), yb.to(device)\n",
    "model.train()\n",
    "logits = model(xb)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "loss = criterion(logits, yb)\n",
    "print(\"Loss:\", float(loss))\n",
    "optimizer.zero_grad(set_to_none=True); loss.backward(); optimizer.step()\n",
    "print(\"Smoke test OK ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0cf3f-e19e-4c34-9914-8677d98ea0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\"train_acc\":[], \"val_acc\":[]}\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    n, tl, ta = 0, 0.0, 0.0\n",
    "    all_p, all_t = [], []\n",
    "    for xb, yb in val_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        b = yb.size(0)\n",
    "        n += b; tl += loss.item()*b; ta += accuracy(logits, yb)*b\n",
    "        all_p.append(logits.argmax(1).cpu().numpy()); all_t.append(yb.cpu().numpy())\n",
    "    return tl/n, ta/n, np.concatenate(all_p), np.concatenate(all_t)\n",
    "\n",
    "def train():\n",
    "    best = 0.0\n",
    "    for e in range(1, CFG[\"epochs\"]+1):\n",
    "        model.train(); n=0; tl=0.0; ta=0.0; t0=time.time()\n",
    "        for xb, yb in train_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb); loss = criterion(logits, yb)\n",
    "            optimizer.zero_grad(set_to_none=True); loss.backward(); optimizer.step()\n",
    "            b = yb.size(0); n += b; tl += loss.item()*b; ta += accuracy(logits, yb)*b\n",
    "        scheduler.step()\n",
    "        vl, va, _, _ = evaluate()\n",
    "        history[\"train_acc\"].append(ta/n); history[\"val_acc\"].append(va)\n",
    "        print(f\"Epoch {e:02d} | train_loss {tl/n:.4f} acc {ta/n:.4f} | val_loss {vl:.4f} acc {va:.4f} | {time.time()-t0:.1f}s\")\n",
    "        if va > best:\n",
    "            best = va\n",
    "            torch.save({\"model\": model.state_dict()}, \"best.pt\")\n",
    "    print(\"Best val acc:\", best)\n",
    "\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fbf31d-2d06-4cc7-96b9-94f7a8360dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vl, va, preds, tgts = evaluate()\n",
    "print(f\"\\nFINAL — Val loss: {vl:.4f} | Val accuracy: {va:.4f}\\n\")\n",
    "print(classification_report(tgts, preds, target_names=[BRACKET_NAMES[i] for i in range(4)]))\n",
    "\n",
    "cm = confusion_matrix(tgts, preds, labels=[0,1,2,3])\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "im = ax.imshow(cm, cmap='Blues')\n",
    "ax.set_xticks(range(4)); ax.set_yticks(range(4))\n",
    "ax.set_xticklabels([BRACKET_NAMES[i] for i in range(4)], rotation=30, ha='right')\n",
    "ax.set_yticklabels([BRACKET_NAMES[i] for i in range(4)])\n",
    "for (i,j), v in np.ndenumerate(cm):\n",
    "    ax.text(j, i, int(v), ha='center', va='center')\n",
    "ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\"); ax.set_title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"train_acc\"], label=\"Train Acc\")\n",
    "plt.plot(history[\"val_acc\"], label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend(); plt.title(\"Accuracy per Epoch\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a14043-3002-4549-9e19-f06b22ba468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"best.pt\", map_location=device)\n",
    "model.load_state_dict(ckpt[\"model\"]); model.eval()\n",
    "\n",
    "infer_tf = transforms.Compose([\n",
    "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_image(path):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    x = infer_tf(img).unsqueeze(0).to(device)\n",
    "    logits = model(x)\n",
    "    probs = logits.softmax(1).cpu().numpy()[0]\n",
    "    k = int(np.argmax(probs))\n",
    "    return {\n",
    "        \"pred_bracket_id\": k,\n",
    "        \"pred_bracket_name\": BRACKET_NAMES[k],\n",
    "        \"probs\": {BRACKET_NAMES[i]: float(probs[i]) for i in range(4)}\n",
    "    }\n",
    "\n",
    "\n",
    "predict_image(r\"G:\\Other computers\\Dell G3\\Universitat\\2nd Semester\\MLMM\\New\\Images\\unitcell_row_0123.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf59b3a-1c93-44b0-a8b7-12aac8932fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
