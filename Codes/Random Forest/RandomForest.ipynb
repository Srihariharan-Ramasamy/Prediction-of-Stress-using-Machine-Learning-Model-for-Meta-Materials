{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddc8c3c6-2b36-443b-a268-6c518ce47804",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddc8c3c6-2b36-443b-a268-6c518ce47804",
        "outputId": "5e68b324-2d50-460c-a8e2-ef58a4dd3d58"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, classification_report, confusion_matrix,\n",
        "    ConfusionMatrixDisplay, log_loss, top_k_accuracy_score, roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# 1) Loading the data\n",
        "file_path1 = \"/content/drive/MyDrive/feature_engineered_with_pca_optimal.csv\"\n",
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv(file_path1)\n",
        "\n",
        "df1 = df1.loc[:, ~df1.columns.astype(str).str.startswith(\"Unnamed\")]\n",
        "\n",
        "# 1-based to 0-based slicing:\n",
        "X_df1 = df1.iloc[:, 0:35]\n",
        "\n",
        "\n",
        "# Convert labels from one-hot to 0..3\n",
        "y1 = df1.iloc[:,35]\n",
        "\n",
        "\n",
        "# 2) Train/test splitting\n",
        "X_train_df, X_test_df, y_train, y_test = train_test_split(\n",
        "    X_df1, y1, test_size=0.2, random_state=42, stratify=y1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72ef903c-0a33-409f-b793-3d03f6a76f6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "72ef903c-0a33-409f-b793-3d03f6a76f6c",
        "outputId": "f53c3fb1-3d4f-4a67-d747-8b86929f55d4"
      },
      "outputs": [],
      "source": [
        "#Random Forest CV sweep\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import log_loss, accuracy_score, f1_score\n",
        "\n",
        "# Base RF pipeline\n",
        "rf_pipe = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"clf\", RandomForestClassifier(\n",
        "        class_weight=\"balanced_subsample\",\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        oob_score=False\n",
        "    )),\n",
        "])\n",
        "\n",
        "# Cross Validation + scoring\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "scoring = {\n",
        "    \"neg_log_loss\": \"neg_log_loss\",\n",
        "    \"accuracy\": \"accuracy\",\n",
        "    \"f1_macro\": \"f1_macro\",\n",
        "}\n",
        "\n",
        "# Search of parameters\n",
        "param_dist = {\n",
        "    \"clf__n_estimators\": [400, 600, 800, 1000],\n",
        "    \"clf__max_depth\": [None, 4, 6, 8, 10],\n",
        "    \"clf__max_features\": [\"sqrt\", \"log2\", 0.5],\n",
        "    \"clf__min_samples_leaf\": [5, 10, 20],\n",
        "    \"clf__min_samples_split\": [10, 20, 40],\n",
        "    \"clf__max_leaf_nodes\": [None, 32, 64, 128],\n",
        "    \"clf__bootstrap\": [True],\n",
        "    \"clf__max_samples\": [0.6, 0.7, 0.8, 0.9],\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    rf_pipe,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=60,\n",
        "    cv=cv,\n",
        "    scoring=scoring,\n",
        "    refit=\"neg_log_loss\",\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Start search\n",
        "search.fit(X_train_df, y_train)\n",
        "\n",
        "# CV results table\n",
        "cvres = pd.DataFrame(search.cv_results_)\n",
        "rf_results = (\n",
        "    cvres\n",
        "      .assign(\n",
        "          train_logloss = -cvres[\"mean_train_neg_log_loss\"],\n",
        "          cv_logloss    = -cvres[\"mean_test_neg_log_loss\"],\n",
        "          train_acc     =  cvres[\"mean_train_accuracy\"],\n",
        "          cv_acc        =  cvres[\"mean_test_accuracy\"],\n",
        "          train_f1_macro=  cvres[\"mean_train_f1_macro\"],\n",
        "          cv_f1_macro   =  cvres[\"mean_test_f1_macro\"],\n",
        "      )[\n",
        "          [\n",
        "            \"param_clf__n_estimators\",\"param_clf__max_depth\",\"param_clf__max_features\",\n",
        "            \"param_clf__min_samples_split\",\"param_clf__min_samples_leaf\",\"param_clf__max_leaf_nodes\",\n",
        "            \"param_clf__bootstrap\",\"param_clf__max_samples\",\n",
        "            \"train_logloss\",\"cv_logloss\",\"train_acc\",\"cv_acc\",\"train_f1_macro\",\"cv_f1_macro\"\n",
        "          ]\n",
        "      ]\n",
        "      .rename(columns={\n",
        "          \"param_clf__n_estimators\":\"n_estimators\",\n",
        "          \"param_clf__max_depth\":\"max_depth\",\n",
        "          \"param_clf__max_features\":\"max_features\",\n",
        "          \"param_clf__min_samples_split\":\"min_samples_split\",\n",
        "          \"param_clf__min_samples_leaf\":\"min_samples_leaf\",\n",
        "          \"param_clf__max_leaf_nodes\":\"max_leaf_nodes\",\n",
        "          \"param_clf__bootstrap\":\"bootstrap\",\n",
        "          \"param_clf__max_samples\":\"max_samples\",\n",
        "      })\n",
        "      .sort_values(\"cv_logloss\", ascending=True)\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "display(rf_results)\n",
        "\n",
        "# Best parameters after analysis\n",
        "print(\"\\nBest by CV log-loss:\")\n",
        "print(search.best_params_)\n",
        "print(f\"Best CV log-loss: {-search.best_score_:.5f}\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.scatter(rf_results[\"n_estimators\"], rf_results[\"cv_logloss\"])\n",
        "plt.xlabel(\"n_estimators\"); plt.ylabel(\"CV Log-loss (lower is better)\")\n",
        "plt.title(\"RandomizedSearchCV — CV Log-loss vs n_estimators\")\n",
        "plt.grid(True); plt.show()\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.scatter(rf_results[\"n_estimators\"], rf_results[\"cv_f1_macro\"])\n",
        "plt.xlabel(\"n_estimators\"); plt.ylabel(\"CV F1 (macro)\")\n",
        "plt.title(\"RandomizedSearchCV — CV F1 (macro) vs n_estimators\")\n",
        "plt.grid(True); plt.show()\n",
        "\n",
        "# Final model\n",
        "rf_final = search.best_estimator_\n",
        "rf_final.fit(X_train_df, y_train)\n",
        "\n",
        "\n",
        "proba_test = rf_final.predict_proba(X_test_df)\n",
        "pred_test  = rf_final.predict(X_test_df)\n",
        "\n",
        "test_logloss  = log_loss(y_test, proba_test, labels=np.unique(y_train))\n",
        "test_acc      = accuracy_score(y_test, pred_test)\n",
        "test_f1_macro = f1_score(y_test, pred_test, average=\"macro\")\n",
        "\n",
        "print(f\"\\nTest log-loss: {test_logloss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test F1 (macro): {test_f1_macro:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jwIOBaNsRIyS",
      "metadata": {
        "id": "jwIOBaNsRIyS"
      },
      "source": [
        "The results (macro-F1) of RF were not as good as the XGBoost, thus we continue with the XGBoost for rest of analysis"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
